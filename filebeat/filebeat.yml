filebeat.inputs:

  - type: filestream
    id: json-collector
    enabled: true
    paths:
      - /var/log/app/*.json
    parsers:
      - ndjson:
        overwrite_keys: true
        add_error_key: true
        expand_keys: true

processors:
  # decode the log field (sub JSON document) if JSON encoded, then maps it's fields to elasticsearch fields
  - decode_json_fields:
      fields: ["log", "message", "msg"]
      target: ""
      # overwrite existing target elasticsearch fields while decoding json fields
      overwrite_keys: true
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_docker_metadata: ~

filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml
  reload.enabled: false

# setup filebeat to send output to elasticsearch
# output.elasticsearch:
#  hosts: [ "http://elasticsearch:9200" ]

# setup filebeat to send output to logstash
output.logstash:
  hosts: ["logstash"]

# Write Filebeat own logs only to file to avoid catching them with itself in docker log files
logging.level: info
logging.to_files: false
logging.to_syslog: false
loggins.metrice.enabled: false
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
ssl.verification_mode: none
